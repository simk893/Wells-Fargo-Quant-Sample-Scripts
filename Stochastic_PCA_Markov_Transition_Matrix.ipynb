{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "import numpy\n",
    "import seaborn\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FRED_data(series_id, retries=5):\n",
    "    API_KEY = 'b4faab7a30a17140d246cce49bbf42ac'\n",
    "    BASE_URL = 'https://api.stlouisfed.org/fred/series/observations'\n",
    "    parameters = {\n",
    "        'series_id': series_id,\n",
    "        'api_key': API_KEY,\n",
    "        'file_type': 'json'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        response = requests.get(BASE_URL, params=parameters)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Create DataFrame and process data\n",
    "            df = pandas.DataFrame(data['observations'])[['date', 'value']]\n",
    "            df['date'] = pandas.to_datetime(df['date'])\n",
    "            df['value'] = pandas.to_numeric(df['value'], errors='coerce')\n",
    "            \n",
    "            # Generate full date range and reindex DataFrame\n",
    "            full_dates = pandas.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n",
    "            df.set_index('date', inplace=True)\n",
    "            df = df.reindex(full_dates)\n",
    "            \n",
    "            # Interpolate missing values\n",
    "            df[series_id] = df['value'].interpolate(method='linear').values\n",
    "            df.drop(columns=['value'], inplace=True)\n",
    "            return df\n",
    "\n",
    "        elif response.status_code == 429:\n",
    "            wait_time = 10\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for series ID {series_id}. Status code: {response.status_code}\")\n",
    "    \n",
    "    print(f\"Failed to fetch data for series ID {series_id} after {retries} retries.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_FRED_dataframe(input_data, start_criteria='2000-01-01'):\n",
    "    df = None\n",
    "    if isinstance(input_data, dict):\n",
    "        series_ids = input_data.keys()\n",
    "    elif isinstance(input_data, str):\n",
    "        series_ids = [input_data]\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dictionary or a string representing a series ID.\")\n",
    "    \n",
    "    for series_id in series_ids:\n",
    "        series_info = input_data[series_id]\n",
    "        observation_start = series_info['observation_start']\n",
    "        \n",
    "        if observation_start <= start_criteria:\n",
    "            data = get_FRED_data(series_id)\n",
    "            if data is None:\n",
    "                print(f\"Failed to fetch data for series ID {series_id}.\")\n",
    "                continue\n",
    "            if df is None:\n",
    "                df = data[data.index >= pandas.to_datetime(start_criteria)]\n",
    "            else:\n",
    "                data = data[data.index >= pandas.to_datetime(start_criteria)]\n",
    "                df = df.merge(data, left_index=True, right_index=True, how='outer')\n",
    "        else:\n",
    "            print(f\"Skipping series ID {series_id} due to observation start date {observation_start}.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the quarterly series data from a CSV file\n",
    "DF = pandas.read_json(r\"C:\\Users\\simeo\\OneDrive\\Attachments\\Projects\\Independent\\Quarterly_Series.json\")\n",
    "\n",
    "# Standardize the data before applying PCA\n",
    "DF.dropna(inplace=True)\n",
    "DF = DF.pct_change() * 100\n",
    "DF.replace([numpy.inf, -numpy.inf], numpy.nan, inplace=True)\n",
    "DF.fillna(0, inplace=True)\n",
    "FRED_Data_scaled = StandardScaler().fit_transform(DF)\n",
    "\n",
    "# Plot the correlation matrix\n",
    "correlation_matrix = pandas.DataFrame(FRED_Data_scaled, columns=DF.columns).corr()\n",
    "seaborn.heatmap(correlation_matrix, annot=False, cmap='coolwarm', xticklabels=True, yticklabels=True)\n",
    "matplotlib.pyplot.xticks(fontsize=5)\n",
    "matplotlib.pyplot.yticks(fontsize=5)\n",
    "matplotlib.pyplot.title('Correlation Matrix')\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=10)\n",
    "principal_components = pca.fit_transform(FRED_Data_scaled)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "principal_df = pandas.DataFrame(data=principal_components, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10'])\n",
    "\n",
    "# Plot the histogram of the variance explained by each principal component\n",
    "explained_variance = pca.explained_variance_ratio_ * 100\n",
    "matplotlib.pyplot.bar(range(1, len(explained_variance) + 1), explained_variance)\n",
    "matplotlib.pyplot.xlabel('Principal Component')\n",
    "matplotlib.pyplot.ylabel('Variance Explained (%)')\n",
    "matplotlib.pyplot.title('Variance Explained by Principal Components')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of principal components to plot\n",
    "K = 3\n",
    "components = pca.components_[:K]\n",
    "components_df = pandas.DataFrame(components, columns=DF.columns, index=[f'PC{i+1}' for i in range(K)])\n",
    "\n",
    "# Plot the principal components as a bar graph\n",
    "components_df.T.plot(kind='bar', figsize=(14, 8))\n",
    "matplotlib.pyplot.xlabel('Variables')\n",
    "matplotlib.pyplot.ylabel('Principal Component Loading')\n",
    "matplotlib.pyplot.title(f'Principal Component Loadings for First {K} PCs')\n",
    "matplotlib.pyplot.legend(title='Principal Components')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_histograms(df, K):\n",
    "    # Plot histograms for the first K principal components\n",
    "    fig, axes = matplotlib.pyplot.subplots(nrows=1, ncols=K, figsize=(14, 6))\n",
    "    for i in range(K):\n",
    "        pc = principal_df[f'PC{i+1}']\n",
    "        axes[i].hist(pc, bins=1000, edgecolor='black')\n",
    "        axes[i].set_xlabel(f'PC{i+1} Values')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].set_title(f'Distribution of PC{i+1} Values')\n",
    "\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_pca_histograms(principal_df, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(principal_df, K):\n",
    "\n",
    "    # Extract the principal components\n",
    "    pcs = [principal_df[f'PC{i+1}'] for i in range(K)]\n",
    "    means = [pc.mean() for pc in pcs]\n",
    "    stds = [pc.std() for pc in pcs]\n",
    "\n",
    "    # Define the standard deviation ranges\n",
    "    std_ranges = [-2, -1, 1, 2]\n",
    "\n",
    "    # Function to categorize the values into standard deviation ranges\n",
    "    def categorize_std(value, mean, std):\n",
    "        if value < mean - std:\n",
    "            return -2\n",
    "        elif value <= mean and value >= mean - std:\n",
    "            return -1\n",
    "        elif value > mean and value <= mean + std:\n",
    "            return 1\n",
    "        elif value > mean + std:\n",
    "            return 2\n",
    "\n",
    "    # Categorize the principal component values\n",
    "    categories = [pc.apply(categorize_std, args=(mean, std)) for pc, mean, std in zip(pcs, means, stds)]\n",
    "\n",
    "    # Initialize the transition matrix\n",
    "    num_states = len(std_ranges) ** K\n",
    "    transition_matrix = numpy.zeros((num_states, num_states))\n",
    "\n",
    "    # Count the transitions\n",
    "    for i in range(1, len(categories[0])):\n",
    "        from_state = tuple(std_ranges.index(categories[j].iloc[i-1]) for j in range(K))\n",
    "        to_state = tuple(std_ranges.index(categories[j].iloc[i]) for j in range(K))\n",
    "        from_index = sum(from_state[j] * (len(std_ranges) ** (K - j - 1)) for j in range(K))\n",
    "        to_index = sum(to_state[j] * (len(std_ranges) ** (K - j - 1)) for j in range(K))\n",
    "        transition_matrix[from_index, to_index] += 1\n",
    "\n",
    "    # Normalize to get probabilities\n",
    "    transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    # Convert to DataFrame for better readability\n",
    "    index_labels = [f'{std_ranges[(i // (len(std_ranges) ** (K - j - 1))) % len(std_ranges)]}' for i in range(num_states) for j in range(K)]\n",
    "    index_labels = [f'{\" \".join([f\"+{label}\" if float(label) > 0 else label for label in index_labels[i:i+K]])}' for i in range(0, len(index_labels), K)]\n",
    "    transition_df = pandas.DataFrame(transition_matrix, index=index_labels, columns=index_labels)\n",
    "    transition_df.index.name = 'From'\n",
    "    transition_df.columns.name = 'To'\n",
    "\n",
    "    # Plot the transition matrix as a heatmap\n",
    "    matplotlib.pyplot.figure(figsize=(12, 10))\n",
    "    seaborn.heatmap(transition_df, annot=False, fmt='0.2f', cmap='Greys', cbar=True, xticklabels=True, yticklabels=True, vmin=0, vmax=1)\n",
    "    matplotlib.pyplot.title('Markov Transition Matrix')\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    return transition_df\n",
    "\n",
    "# Example usage:\n",
    "transition_df = create_transition_matrix(principal_df, K)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
